# -*- coding: utf-8 -*-
"""camaroes_sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U2OJ-QEuMRUKy2f5vlHojOoYfrQOhhii

# Normalização
"""

import pandas as pd
import string
import re
import unidecode
import nltk
from nltk.tokenize import word_tokenize, RegexpTokenizer
nltk.download('vader_lexicon')
from nltk.sentiment import SentimentIntensityAnalyzer
#from translate import Translator
from googletrans import Translator
import tqdm
import time
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import csv

nltk.download('stopwords')

df = pd.read_csv("C:\\Users\\Gusto\\Desktop\\projects\\ml-sentiment_analysis\\camaroes.csv")
df.head()

df["Comentarios"].describe()

df["Comentarios"].unique()

df["Estrelas"].describe()

def converter_minusculo(text):
    return text.lower()

def remove_espaco_branco(text):
    return text.strip()

def remove_pontuacao(text):
    punct_str = string.punctuation
    punct_str = punct_str.replace("'", "")
    translator = str.maketrans("", "", punct_str)
    return text.translate(translator)

def remove_emoji(text):
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"
        u"\U0001F300-\U0001F5FF"
        u"\U0001F680-\U0001F6FF"
        u"\U0001F1E0-\U0001F1FF"
        u"\U00002702-\U000027B0"
        u"\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r"", text)

def remove_http(text):
    http = r"https?:\/\/(?:www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b(?:[-a-zA-Z0-9()@:%_\+.~#?&\/=]*)"
    pattern = re.compile(http, re.IGNORECASE)
    return pattern.sub("", text)

regexp = RegexpTokenizer(r"\b\w+\b")
linguas = ['portuguese', 'english', 'spanish', 'french']
stops = []
for lingua in linguas:
    stops += nltk.corpus.stopwords.words(lingua)
def remove_stopwords(text):
    return " ".join([word for word in regexp.tokenize(text) if word not in stops])

def text_normalizer(text):
    text = unidecode.unidecode(text)
    text = re.sub('\n', '', text)
    text = remove_http(text)
    text = remove_emoji(text)
    text = remove_pontuacao(text)
    text = remove_espaco_branco(text)
    text = converter_minusculo(text)
    text = remove_stopwords(text)
    return text

print("{}".format(text_normalizer(df.iloc[0,2])))

data = pd.DataFrame()
data["titulo_norm"] = df["Título"].apply(text_normalizer)
data["Coments_norm"] = df["Comentarios"].apply(text_normalizer)
df["Coments_norm"] = data["Coments_norm"].to_list()

data["Estrelas"] = df["Estrelas"]
data.head()

"""# Análise de sentimentos"""

sia = SentimentIntensityAnalyzer()

#translator = Translator(from_lang="pt-br", to_lang="en")
translator = Translator()

traducao = translator.translate(data.iloc[0]["Coments_norm"])

x = sia.polarity_scores(traducao.text)
x

def traduzir(text):
    #translator = Translator(from_lang="pt-br", to_lang="en")
    #traducao = translator.translate(str(text))
    translator = Translator()
    traducao = translator.translate(str(text), dest='en').text
    return traducao

t = traduzir('olá')

df2 = data.head(50)

pol = []
cont = 0

inicio = time.time()
for i, row in data.iterrows():

    text = row['Coments_norm']
    text_t = traduzir(text)
    text_t_norm = text_normalizer(text_t)
    print(cont)
    cont+=1
    time.sleep(2)
    pol.append(sia.polarity_scores(text_t_norm))
    data.loc[i, 'Coments_norm'] = text_t_norm
fim = time.time()

print(f'Tempo total: {fim-inicio} segundos')
print(f'Tempo total: {(fim-inicio)/60} minutos')

data['Polarity Scores'] = pol

sia_stars = []
for score in pol:
    compound = score['compound']
    neg = score['neg']
    neu = score['neu']
    pos = score['pos']

    if compound >= 0.7 and pos > neg and pos > neu/2:
        sia_stars.append(5)  # Muito positivo
    elif compound >= 0.3 and pos > neg:
        sia_stars.append(4)  # Positivo
    elif compound >= 0.05 and pos > neg - 0.1 and pos > neu/3:
        sia_stars.append(3) # Neutro tendendo ao positivo
    elif compound <= -0.7 and neg > pos:
        sia_stars.append(1)  # Muito negativo
    elif compound <= -0.3 and neg > pos :
        sia_stars.append(2)  # Negativo
    elif neg > pos + 0.2 and neg > neu/3 :
        sia_stars.append(2) # Neutro tendendo ao negativo
    else:
        sia_stars.append(3)  # Neutro

data['Estrelas SIA'] = sia_stars

polarity = []
for i, row in data.iterrows():
    compound = row['Polarity Scores']['compound']
    neg = row['Polarity Scores']['neg']
    neu = row['Polarity Scores']['neu']
    pos = row['Polarity Scores']['pos']

    if compound >= 0.05 and pos > neg and pos > neu/2.5 :  # Positivo se compound positivo e pos > neg
            polarity.append("positivo")
    elif compound <= -0.05 and neg > pos:  # Negativo se compound negativo e neg > pos
            polarity.append("negativo")
    elif pos > neg + 2: # Positivo se pos for significativamente maior que neg (neutro com tendência positiva)
            polarity.append("positivo")
    elif neg > pos + 2: # Negativo se neg for significativamente maior que pos (neutro com tendência negativa)
            polarity.append("negativo")
    else: # Neutro se pos e neg forem semelhantes ou se o compound estiver próximo de 0
            polarity.append("neutro")

def classificar_estrelas(estrelas):
    if estrelas >= 4:
        return "positivo"
    elif estrelas <= 2:
        return "negativo"
    else:
        return "neutro"

data['classificacao_estrelas'] = data['Estrelas'].apply(classificar_estrelas)

data['polaridade'] = polarity

with open('C:\\Users\\Gusto\\Desktop\\projects\\ml-sentiment_analysis\\camaroes_sia_stars.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(['Index', 'Coments_norm', 'Estrelas SIA', 'Estrelas', 'Polarity Scores'])
    #writer.writerow(['Index', 'Coments_norm', 'Estrelas SIA', 'Estrelas', 'Classificacao_estrelas'])

    for index, row in data.iterrows():
        writer.writerow([index + 1, row['Coments_norm'], row['Estrelas SIA'], row['Estrelas'], row['Polarity Scores']])
        #writer.writerow([index + 1, row['Coments_norm'], row['Estrelas SIA'], row['Estrelas'], row['classificacao_estrelas']])